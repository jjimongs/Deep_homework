{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# a_tensor_initialization.py"
      ],
      "metadata": {
        "id": "o8cEYA_kmFlb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "uDmlEUMKl4cH"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t1 = torch.Tensor([1,2,3], device ='cpu')\n",
        "print(t1.dtype)\n",
        "print(t1.device)\n",
        "print(t1.requires_grad)\n",
        "print(t1.size())\n",
        "print(t1.shape)\n",
        "\n",
        "t1_cpu = t1.cpu()\n",
        "print(\"#\"*50, 1)"
      ],
      "metadata": {
        "id": "XwDcQgMpmO2i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7c4f4da-81b4-4708-af72-7295ef521617"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.float32\n",
            "cpu\n",
            "False\n",
            "torch.Size([3])\n",
            "torch.Size([3])\n",
            "################################################## 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t2 = torch.tensor([1,2,3], device='cpu')\n",
        "print(t2.dtype)\n",
        "print(t2.device)\n",
        "print(t2.requires_grad)\n",
        "print(t2.size())\n",
        "print(t2.shape)\n",
        "\n",
        "t2_cpu = t2.cpu()\n",
        "print(\"#\"*50, 2)"
      ],
      "metadata": {
        "id": "qeMAa4uWesSR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "637523b4-5020-44c3-db3f-1bfb61976268"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.int64\n",
            "cpu\n",
            "False\n",
            "torch.Size([3])\n",
            "torch.Size([3])\n",
            "################################################## 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a1 = torch.tensor(1)\t\t\t           # shape: torch.Size([]), ndims(=rank): 0\n",
        "print(a1.shape, a1.ndim)\n",
        "\n",
        "a2 = torch.tensor([1])\t\t  \t       # shape: torch.Size([1]), ndims(=rank): 1\n",
        "print(a2.shape, a2.ndim)\n",
        "\n",
        "a3 = torch.tensor([1, 2, 3, 4, 5])   # shape: torch.Size([5]), ndims(=rank): 1\n",
        "print(a3.shape, a3.ndim)\n",
        "\n",
        "a4 = torch.tensor([[1], [2], [3], [4], [5]])   # shape: torch.Size([5, 1]), ndims(=rank): 2\n",
        "print(a4.shape, a4.ndim)"
      ],
      "metadata": {
        "id": "1k0jvpEzextu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2949c37d-cd5e-43f0-f76c-2d16e5f6a890"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([]) 0\n",
            "torch.Size([1]) 1\n",
            "torch.Size([5]) 1\n",
            "torch.Size([5, 1]) 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a5 = torch.tensor([                 # shape: torch.Size([3, 2]), ndims(=rank): 2\n",
        "    [1, 2],\n",
        "    [3, 4],\n",
        "    [5, 6]\n",
        "])\n",
        "print(a5.shape, a5.ndim)\n",
        "\n",
        "a6 = torch.tensor([                 # shape: torch.Size([3, 2, 1]), ndims(=rank): 3\n",
        "    [[1], [2]],\n",
        "    [[3], [4]],\n",
        "    [[5], [6]]\n",
        "])\n",
        "print(a6.shape, a6.ndim)\n",
        "\n",
        "a7 = torch.tensor([                 # shape: torch.Size([3, 1, 2, 1]), ndims(=rank): 4\n",
        "    [[[1], [2]]],\n",
        "    [[[3], [4]]],\n",
        "    [[[5], [6]]]\n",
        "])\n",
        "print(a7.shape, a7.ndim)\n",
        "\n",
        "a8 = torch.tensor([                 # shape: torch.Size([3, 1, 2, 3]), ndims(=rank): 4\n",
        "    [[[1, 2, 3], [2, 3, 4]]],\n",
        "    [[[3, 1, 1], [4, 4, 5]]],\n",
        "    [[[5, 6, 2], [6, 3, 1]]]\n",
        "])\n",
        "print(a8.shape, a8.ndim)\n",
        "\n",
        "\n",
        "a9 = torch.tensor([                 # shape: torch.Size([3, 1, 2, 3, 1]), ndims(=rank): 5\n",
        "    [[[[1], [2], [3]], [[2], [3], [4]]]],\n",
        "    [[[[3], [1], [1]], [[4], [4], [5]]]],\n",
        "    [[[[5], [6], [2]], [[6], [3], [1]]]]\n",
        "])\n",
        "print(a9.shape, a9.ndim)"
      ],
      "metadata": {
        "id": "44ylUO0Be04m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20d9d621-193a-467f-cd38-ff3985800a4a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 2]) 2\n",
            "torch.Size([3, 2, 1]) 3\n",
            "torch.Size([3, 1, 2, 1]) 4\n",
            "torch.Size([3, 1, 2, 3]) 4\n",
            "torch.Size([3, 1, 2, 3, 1]) 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a10 = torch.tensor([                 # shape: torch.Size([4, 1, 5]), ndims(=rank): 3\n",
        "    [[1, 2, 3, 4, 5]],\n",
        "    [[1, 2, 3, 4, 5]],\n",
        "    [[1, 2, 3, 4, 5]],\n",
        "    [[1, 2, 3, 4, 5]],\n",
        "])\n",
        "print(a10.shape, a10.ndim)\n",
        "\n",
        "a11 = torch.tensor([                 # ValueError: expected sequence of length 3 at dim 3 (got 2)\n",
        "    [[[1, 2, 3], [4, 5]]],\n",
        "    [[[1, 2, 3], [4, 5]]],\n",
        "    [[[1, 2, 3], [4, 5]]],\n",
        "    [[[1, 2, 3], [4, 5]]],\n",
        "])"
      ],
      "metadata": {
        "id": "fkwF1Z88e8jm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 276
        },
        "outputId": "05721060-ffb4-48c6-b8f5-d5e20adc67cd"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 1, 5]) 3\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-8e3489880739>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma10\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma10\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m a11 = torch.tensor([                 # ValueError: expected sequence of length 3 at dim 3 (got 2)\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: expected sequence of length 3 at dim 3 (got 2)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# b tensor_initialization_copy.py"
      ],
      "metadata": {
        "id": "EgImbJJCpS2u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Python list나 Numpy 배열을 PyTorch 텐서로 변환하는 방법\n",
        "l1 = [1, 2, 3]\n",
        "t1 = torch.Tensor(l1)\n",
        "\n",
        "l2 = [1, 2, 3]\n",
        "t2 = torch.tensor(l2)\n",
        "\n",
        "l3 = [1, 2, 3]\n",
        "t3 = torch.as_tensor(l3)        # 텐서인 경우, 기존 텐서 그대로 반환 (이 경우 그대로 반환하고 있음)\n",
        "\n",
        "\n",
        "l1[0] = 100\n",
        "l2[0] = 100\n",
        "l3[0] = 100\n",
        "\n",
        "print(t1)           # 입력 데이터 복사하여 새로운 텐서 만들기에 변경되지 X\n",
        "print(t2)           # 입력 데이터 복사하여 새로운 텐서 만들기에 변경되지 X\n",
        "print(t3)           # 텐서인 경우, 기존 텐서를 그대로 반환하기에 변경되지 X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3xpBASbWpcCc",
        "outputId": "952c8078-9047-4dbe-b03d-b29d820490d1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 2., 3.])\n",
            "tensor([1, 2, 3])\n",
            "tensor([1, 2, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "l4 = np.array([1, 2, 3])\n",
        "t4 = torch.Tensor(l4)\n",
        "\n",
        "l5 = np.array([1, 2, 3])\n",
        "t5 = torch.tensor(l5)\n",
        "\n",
        "l6 = np.array([1, 2, 3])\n",
        "t6 = torch.as_tensor(l6)\n",
        "\n",
        "l4[0] = 100\n",
        "l5[0] = 100\n",
        "l6[0] = 100           # 배열이기에 텐서가 아님, 기존 텐서를 그대로 반환하지 않아 값이 100으로 바뀌는 것을 볼 수 있음\n",
        "\n",
        "print(t4)\n",
        "print(t5)\n",
        "print(t6)"
      ],
      "metadata": {
        "id": "EHhc3KkefFc4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6e066bf-030a-4908-b6e6-c52547a20944"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 2., 3.])\n",
            "tensor([1, 2, 3])\n",
            "tensor([100,   2,   3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# c_tensor_initialization_constant_values.py"
      ],
      "metadata": {
        "id": "0OLYzdEXsye-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t1 = torch.ones(size=(5,))\n",
        "t1_like = torch.ones_like(input=t1) # 입력 텐서와 같은 크기와 타입을 갖는 텐서를 생성하고, 모든 요소를 1로 채운다.\n",
        "print(t1)\n",
        "print(t1_like)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QGa0uFjvs8CD",
        "outputId": "e1b13ccd-6a8e-4921-86a5-2ce1c25ce2f8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 1., 1., 1., 1.])\n",
            "tensor([1., 1., 1., 1., 1.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t2 = torch.zeros(size=(6,))\n",
        "t2_like = torch.zeros_like(input=t2)  # 입력 텐서와 같은 크기와 타입을 갖는 텐서를 생성하고, 모든 요소를 0으로 채운다.\n",
        "print(t2)\n",
        "print(t2_like)"
      ],
      "metadata": {
        "id": "aFdiW0a1fL6o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb351683-7892-4990-bfe3-6ae2b33a6ff9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0., 0., 0., 0., 0., 0.])\n",
            "tensor([0., 0., 0., 0., 0., 0.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t3 = torch.empty(size=(4,)) # 주어진 크기의 아무값으로 초기화 되지 않은 텐서를 생성한다.\n",
        "t3_like = torch.empty_like(input=t3)\n",
        "print(t3)\n",
        "print(t3_like)"
      ],
      "metadata": {
        "id": "K2lSoAn7fPo-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15a91553-393b-4ff5-e017-c178c7223171"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1.8682e+12, 4.3554e-41, 1.8682e+12, 4.3554e-41])\n",
            "tensor([4.2490e-05, 8.3026e-10, 2.1707e-18, 4.5447e+30])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t4 = torch.eye(n=3) # 대각이 1이고 나머지가 0인 행렬 생성, 대각행렬이다.\n",
        "print(t4)"
      ],
      "metadata": {
        "id": "dw4F1rTdfQwO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "771bf2ff-b206-4e3d-845e-24c1dcc85083"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 0., 0.],\n",
            "        [0., 1., 0.],\n",
            "        [0., 0., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# d_tensor_initialization_random_values.py"
      ],
      "metadata": {
        "id": "HIt0l3Z3tJ9N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t1 = torch.randint(low=10, high=20, size=(1, 2))          # 10부터 20까지의 정수 중에서 임의로 선택된 2개의 값을 갖는 사이즈가 (1,2)인 텐서를 생성\n",
        "print(t1)\n",
        "\n",
        "t2 = torch.rand(size=(1, 3))                             # 0과 1 사이의 실수를 갖는 사이즈가 (1,3)인 텐서를 생성\n",
        "print(t2)\n",
        "\n",
        "t3 = torch.randn(size=(1, 3))                            # 표준 정규 분포에서 랜덤한 실수를 갖는 사이즈가 (1,3)인 텐서를 생성\n",
        "print(t3)\n",
        "\n",
        "t4 = torch.normal(mean=10.0, std=1.0, size=(3, 2))       # 평균이 10이고 표준 편차가 1인 정규 분포에서 랜덤한 실수를 갖는 사이즈가 (3,2)인 텐서를 생성\n",
        "print(t4)\n",
        "\n",
        "t5 = torch.linspace(start=0.0, end=5.0, steps=3)         # start(0)와 end(5) 사이에서 steps(3) 개수만큼 균등하게 분포된 텐서를 생성\n",
        "print(t5)\n",
        "\n",
        "t6 = torch.arange(5)                                     # 0부터 end(5) 이전까지의 개수만큼의 텐서를 생성\n",
        "print(t6)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X3B65PP6tSFY",
        "outputId": "e5c5a788-5a81-4e1e-cffb-874b39ddc995"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[14, 14]])\n",
            "tensor([[0.4444, 0.4753, 0.1751]])\n",
            "tensor([[-0.9641,  0.1780, -0.3960]])\n",
            "tensor([[ 8.3381, 11.4319],\n",
            "        [11.5396,  9.3473],\n",
            "        [10.6309,  9.5243]])\n",
            "tensor([0.0000, 2.5000, 5.0000])\n",
            "tensor([0, 1, 2, 3, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(1729)\n",
        "random1 = torch.rand(2, 3)                               # random1은 torch.manual_seed(1729) 함수를 호출한 후에 생성된 난수값으로 텐서를 형성한다.\n",
        "print(random1)\n",
        "\n",
        "random2 = torch.rand(2, 3)                               # random2는 torch.manual_seed(1729) 함수를 호출한 후에 생성된 난수값으로 텐서를 형성한다.\n",
        "print(random2)\n",
        "\n",
        "print()\n",
        "\n",
        "torch.manual_seed(1729)\n",
        "random3 = torch.rand(2, 3)                               # random3은 torch.manual_seed(1729) 함수가 다시 한번 호출된 뒤에 난수값을 생성하였기에 random1과 동일한 난수값으로 텐서가 형성한다.\n",
        "print(random3)\n",
        "\n",
        "random4 = torch.rand(2, 3)                               # random4는 torch.manual_seed(1729) 함수가 다시 한번 호출된 뒤에 난수값을 생성하였기에 random2과 동일한 난수값으로 텐서가 형성한다.\n",
        "print(random4)"
      ],
      "metadata": {
        "id": "B_ULwuyCfVQg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03f7cd2b-6b97-4c22-d4db-8dec2d286238"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.3126, 0.3791, 0.3087],\n",
            "        [0.0736, 0.4216, 0.0691]])\n",
            "tensor([[0.2332, 0.4047, 0.2162],\n",
            "        [0.9927, 0.4128, 0.5938]])\n",
            "\n",
            "tensor([[0.3126, 0.3791, 0.3087],\n",
            "        [0.0736, 0.4216, 0.0691]])\n",
            "tensor([[0.2332, 0.4047, 0.2162],\n",
            "        [0.9927, 0.4128, 0.5938]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# e_tensor_type_conversion.py"
      ],
      "metadata": {
        "id": "IlE-A2VftVmL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.ones((2, 3))\n",
        "print(a.dtype)      #텐서의 데이터 타입 (32비트 부동 소수점 타입)\n",
        "\n",
        "b = torch.ones((2, 3), dtype=torch.int16)\n",
        "print(b)            #모든 요소가 1로 채워진 사이즈 (2,3)의 텐서 생성 (16비트 정수 타입)\n",
        "\n",
        "c = torch.rand((2, 3), dtype=torch.float64) * 20.\n",
        "print(c)            #0과 1사이의 실수를 갖는 사이즈 (2,3)의 텐서에 20을 곱하여 생성 (64비트 실수 타입)\n",
        "\n",
        "d = b.to(torch.int32)\n",
        "print(d)            # (2,3) 사이즈의 텐서를 생성하고, 모든 원소를 32비트 정수로 변환한 후에 출력"
      ],
      "metadata": {
        "id": "WM5jvyEMtg5C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b82fdcb6-0cec-4557-b968-9faff3f3465b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.float32\n",
            "tensor([[1, 1, 1],\n",
            "        [1, 1, 1]], dtype=torch.int16)\n",
            "tensor([[18.0429,  7.2532, 19.6519],\n",
            "        [10.8626,  2.1505, 19.6913]], dtype=torch.float64)\n",
            "tensor([[1, 1, 1],\n",
            "        [1, 1, 1]], dtype=torch.int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#텐서의 데이터타입 변환\n",
        "double_d = torch.ones(10, 2, dtype=torch.double)              # 64비트 부동 소수점 텐서를 생성 (사이즈:(10,2))\n",
        "short_e = torch.tensor([[1, 2]], dtype=torch.short)           # 16비트 정수 텐서를 생성 (사이즈:(1,2))\n",
        "\n",
        "double_d = torch.zeros(10, 2).double()                        # 64비트 부동 소수점 텐서를 생성하고, double 메서드를 사용하여 데이터 타입을 64비트 부동 소수점으로 변환\n",
        "short_e = torch.ones(10, 2).short()                           # 16비트 정수 텐서를 생성하고, short 메서드를 사용하여 데이터 타입을 16비트 정수로 변환\n",
        "\n",
        "double_d = torch.zeros(10, 2).to(torch.double)                # to() 메서드를 사용하여 데이터 타입을 64비트 부동 소수점으로 변환\n",
        "short_e = torch.ones(10, 2).to(dtype=torch.short)             # to() 메서드를 사용하여 데이터 타입을 16비트 정로 변환\n",
        "\n",
        "double_d = torch.zeros(10, 2).type(torch.double)              # type() 메서드를 사용하여 데이터 타입을 64비트 부동 소수점으로 변환\n",
        "short_e = torch.ones(10, 2). type(dtype=torch.short)          # type() 메서드를 사용하여 데이터 타입을 16비트 정수로 변환\n",
        "\n",
        "print(double_d.dtype)\n",
        "print(short_e.dtype)\n",
        "\n",
        "double_f = torch.rand(5, dtype=torch.double)\n",
        "short_g = double_f.to(torch.short)\n",
        "print((double_f * short_g).dtype)                             # 두 텐서의 데이터 타입이 다르기 때문에 PyTorch가 두 텐서의 데이터 타입을 공통 분모로 변환"
      ],
      "metadata": {
        "id": "6ill-vDXfafU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7ff076b-f979-4844-cafb-ad510bcad737"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.float64\n",
            "torch.int16\n",
            "torch.float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# f_tensor_operations.py"
      ],
      "metadata": {
        "id": "-A1b_tm8t5F6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t1 = torch.ones(size=(2, 3))\n",
        "t2 = torch.ones(size=(2, 3))\n",
        "t3 = torch.add(t1, t2)       #텐서 더하기(add의 경우, 데이터 타입이 다를 때도 덧셈 가능하다)\n",
        "t4 = t1 + t2                 #텐서 더하기\n",
        "print(t3)\n",
        "print(t4)"
      ],
      "metadata": {
        "id": "A6g7MYhWuAHh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a0d23f1-9fe1-46c3-f880-f94d1e981477"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[2., 2., 2.],\n",
            "        [2., 2., 2.]])\n",
            "tensor([[2., 2., 2.],\n",
            "        [2., 2., 2.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t5 = torch.sub(t1, t2)       #텐서 빼기 (데이터 타입이나 크기가 달라도 뺄셈 가능)\n",
        "t6 = t1 - t2                 #텐서 빼기\n",
        "print(t5)\n",
        "print(t6)"
      ],
      "metadata": {
        "id": "mU2n3OTmfgMo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af523333-88ec-4c72-80e0-7a23c0fba7cd"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.]])\n",
            "tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t7 = torch.mul(t1, t2)       #텐서 곱하기 (데이터 타입이나 크기가 달라도 곱셈 가능)\n",
        "t8 = t1 * t2                 #텐서 곱하기\n",
        "print(t7)\n",
        "print(t8)"
      ],
      "metadata": {
        "id": "ucM5n4NJfiXe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2fe8347d-e27c-49e4-d4db-7f5b465f8378"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.]])\n",
            "tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t9 = torch.div(t1, t2)       #텐서 나누기 (데이터 타입이나 크기가 달라도 나눗셈 가능)\n",
        "t10 = t1 / t2                #텐서 나누기\n",
        "print(t9)\n",
        "print(t10)"
      ],
      "metadata": {
        "id": "nQGpzKrpfkFa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d39d2aad-a72a-45f0-c69b-723177b44dc2"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.]])\n",
            "tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# g_tensor_operations_mm.py\n"
      ],
      "metadata": {
        "id": "Jfm4yi3AvjHq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "t1 = torch.dot(\n",
        "  torch.tensor([2, 3]), torch.tensor([2, 1])\n",
        ")\n",
        "print(t1, t1.size())           #백터의 내적 계산 (t1 = 2 * 2 + 3 * 1=7)\n",
        "\n",
        "t2 = torch.randn(2, 3)         # 사이즈가 (2,3)인 평균이 0이고 표준편차가 1인 정규 분포에서 값 무작위로 초기화\n",
        "t3 = torch.randn(3, 2)         # 사이즈가 (3,2)인 평균이 0이고 표준편차가 1인 정규 분포에서 값 무작위로 초기화\n",
        "t4 = torch.mm(t2, t3)          # 텐서의 행렬 곱셉 실행\n",
        "print(t4, t4.size())\n",
        "\n",
        "t5 = torch.randn(10, 3, 4)     # 10개의 배치가 있고, 각 배치마다 (3,4) 사이즈의 행렬포함\n",
        "t6 = torch.randn(10, 4, 5)     # 10개의 배치가 있고, 각 배치마다 (4,5) 사이즈의 행렬포함\n",
        "t7 = torch.bmm(t5, t6)         # 배치 매트릭스 곱셈 수행\n",
        "print(t7.size())               # 행렬 곱셈 수행하기에 결과와 텐서도 같은 배치 유지됨"
      ],
      "metadata": {
        "id": "XfjrKL_Tvnv9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "494c1bc0-f737-4013-c5d9-11a4f936a483"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(7) torch.Size([])\n",
            "tensor([[1.6750, 2.2840],\n",
            "        [0.0956, 1.0294]]) torch.Size([2, 2])\n",
            "torch.Size([10, 3, 5])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#h_tensor_operations_matmul.py"
      ],
      "metadata": {
        "id": "UtrSwgBJvptF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# vector x vector: dot product\n",
        "t1 = torch.randn(3)\n",
        "t2 = torch.randn(3)\n",
        "print(torch.matmul(t1, t2).size())       # 둘 다 1차원 텐서이기에 내적 수행했을때, 스칼라값을 반환한다.\n",
        "                                         # 스칼라는 차원이 없기에 torch.Size([])가 출력된다."
      ],
      "metadata": {
        "id": "RLVxgFw0vwAk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b389720-0a1d-4fc6-ea7f-8598ab88ef4d"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# matrix x vector: broadcasted dot\n",
        "t3 = torch.randn(3, 4)\n",
        "t4 = torch.randn(4)\n",
        "print(torch.matmul(t3, t4).size())       # 행렬 * 벡터의 값을 수행한다. 행렬 곱셈을 수행했을 때, t3의 행은 t4와 내적되어 스칼라값 반환한다.\n",
        "                                         # 그렇기에 크기가 3인 1차원 벡터인 torch.Size([3])이 출력된다."
      ],
      "metadata": {
        "id": "DUoYl7l6fryv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf004bcb-d693-48d1-af02-c778c47d4dfb"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# batched matrix x vector: broadcasted dot\n",
        "t5 = torch.randn(10, 3, 4)\n",
        "t6 = torch.randn(4)\n",
        "print(torch.matmul(t5, t6).size())       # 배치된 행렬 * 벡터의 값을 수행한다. 행렬 곱셈을 수행했을 때, t5의 배치은 t6와 내적되어 [10,3]을 반환한다.\n",
        "                                         # 그렇기에 크기가 (10,3)인 2차원 벡터인 torch.Size([10,3])이 출력된다."
      ],
      "metadata": {
        "id": "MjeptlhOfuAX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f37d71e-2230-4f1e-8965-48690382c411"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([10, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# batched matrix x batched matrix: bmm\n",
        "t7 = torch.randn(10, 3, 4)\n",
        "t8 = torch.randn(10, 4, 5)\n",
        "print(torch.matmul(t7, t8).size())       # 배치된 행렬 * 배치된 행렬 값을 수행한다. 배치 매트릭스 곱셈을 수행했을 때,[10,3,5]를 반환한다.\n",
        "                                         # 그렇기에 크기가 (10,3,5)인 3차원 벡터인 torch.Size([10,3,5])가 출력된다."
      ],
      "metadata": {
        "id": "7dK0EUg-fvg6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3024051-7b88-4983-c201-6754da9a2034"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([10, 3, 5])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# batched matrix x matrix: bmm\n",
        "t9 = torch.randn(10, 3, 4)\n",
        "t10 = torch.randn(4, 5)\n",
        "print(torch.matmul(t9, t10).size())      # 배치된 행렬 * 행렬 값을 수행한다. 배치 매트릭스 곱셈을 수행했을 때,[10,3,5]를 반환한다.\n",
        "                                         # 그렇기에 크기가 (10,3,5)인 3차원 벡터인 torch.Size([10,3,5])가 출력된다."
      ],
      "metadata": {
        "id": "FjMJ0qgufwvc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "217271b6-a206-4621-f464-25930594dd09"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([10, 3, 5])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# i_tensor_broadcasting.py"
      ],
      "metadata": {
        "id": "s5alyt1LvyoS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t1 = torch.tensor([1.0, 2.0, 3.0])\n",
        "t2 = 2.0\n",
        "print(t1 * t2)                    # 텐서 * 스칼라 곱셈 수행 (각 원소에 broadcasting 되어 원소와의 곱셈이 일어남)"
      ],
      "metadata": {
        "id": "h7MBK8KPvx2R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6231f2b4-6942-4226-b855-17157fd75985"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2., 4., 6.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t3 = torch.tensor([[0, 1], [2, 4], [10, 10]])\n",
        "t4 = torch.tensor([4, 5])\n",
        "print(t3 - t4)                   # 행렬 - 벡터 뺄셈 수행 (broadcasting에 따라 벡터가 행렬의 각 행에 대해 빼기 연산 수행 )"
      ],
      "metadata": {
        "id": "vjCZgLZaf0wI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f440b012-0257-4e66-cbfe-f56a15f693b3"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-4, -4],\n",
            "        [-2, -1],\n",
            "        [ 6,  5]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t5 = torch.tensor([[1., 2.], [3., 4.]])\n",
        "print(t5 + 2.0)  # t5.add(2.0)   #행렬 t5 + 2.0\n",
        "print(t5 - 2.0)  # t5.sub(2.0)   #행렬 t5 - 2.0\n",
        "print(t5 * 2.0)  # t5.mul(2.0)   #행렬 t5 * 2.0\n",
        "print(t5 / 2.0)  # t5.div(2.0)   #행렬 t5 / 2.0"
      ],
      "metadata": {
        "id": "56SYfyncf4mG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc8fec9c-e731-4fc8-e557-f4e8d2524485"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[3., 4.],\n",
            "        [5., 6.]])\n",
            "tensor([[-1.,  0.],\n",
            "        [ 1.,  2.]])\n",
            "tensor([[2., 4.],\n",
            "        [6., 8.]])\n",
            "tensor([[0.5000, 1.0000],\n",
            "        [1.5000, 2.0000]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize(x):                 # 정규화 수행 [0,255] -> [0,1]\n",
        "  return x / 255\n",
        "\n",
        "\n",
        "t6 = torch.randn(3, 28, 28)\n",
        "print(normalize(t6).size())       # 정규화 된 텐서의 크기는 입력 텐서 t6와 동일 (텐서의 차원은 변경되지 X)"
      ],
      "metadata": {
        "id": "6lc_hfYpf7Oe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbdaa668-cea0-4e31-f7f0-59e3c3b046fa"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 28, 28])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t7 = torch.tensor([[1, 2], [0, 3]])  # torch.Size([2, 2])\n",
        "t8 = torch.tensor([[3, 1]])  # torch.Size([1, 2])\n",
        "t9 = torch.tensor([[5], [2]])  # torch.Size([2, 1])\n",
        "t10 = torch.tensor([7])  # torch.Size([1])\n",
        "print(t7 + t8)   # >>> tensor([[4, 3], [3, 4]])\n",
        "print(t7 + t9)   # >>> tensor([[6, 7], [2, 5]])\n",
        "print(t8 + t9)   # >>> tensor([[8, 6], [5, 3]])\n",
        "print(t7 + t10)  # >>> tensor([[ 8, 9], [ 7, 10]])"
      ],
      "metadata": {
        "id": "60M_0jkTf93C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "085e897f-fe9f-4157-b86f-259eb910e3db"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[4, 3],\n",
            "        [3, 4]])\n",
            "tensor([[6, 7],\n",
            "        [2, 5]])\n",
            "tensor([[8, 6],\n",
            "        [5, 3]])\n",
            "tensor([[ 8,  9],\n",
            "        [ 7, 10]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t11 = torch.ones(4, 3, 2)\n",
        "t12 = t11 * torch.rand(3, 2)  # 3rd & 2nd dims identical to t11, dim 0 absent\n",
        "print(t12.shape)              # t11에 t12를 곱하여 broadcasting 된 연산은 텐서가 (4,3,2)크기와 호환되도록 확장하여 크기가 (4,3,2)로 유지됨\n",
        "\n",
        "t13 = torch.ones(4, 3, 2)\n",
        "t14 = t13 * torch.rand(3, 1)  # 3rd dim = 1, 2nd dim is identical to t13\n",
        "print(t14.shape)              # t13에 t14를 곱하여 broadcasting 된 연산은 텐서가 (4,3,2)크기와 호환되도록 확장하여 크기가 (4,3,2)로 유지됨\n",
        "\n",
        "t15 = torch.ones(4, 3, 2)\n",
        "t16 = t15 * torch.rand(1, 2)  # 3rd dim is identical to t15, 2nd dim is 1\n",
        "print(t16.shape)              # t15에 t16를 곱하여 broadcasting 된 연산은 텐서가 (4,3,2)크기와 호환되도록 확장하여 크기가 (4,3,2)로 유지됨\n",
        "\n",
        "t17 = torch.ones(5, 3, 4, 1)\n",
        "t18 = torch.rand(3, 1, 1)     # 2nd dim is identical to t17, 3rd and 4th dims are 1\n",
        "print((t17 + t18).size())     # t17에 t18를 곱하여 broadcasting 된 연산은 텐서가 (5,3,4,1)크기와 호환되도록 확장하여 크기가 (5,3,4,1)로 유지됨"
      ],
      "metadata": {
        "id": "Z1-1GEaXf_qp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58d6106c-1ef3-46f6-cfc6-3cfae79aa0d6"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 2])\n",
            "torch.Size([4, 3, 2])\n",
            "torch.Size([4, 3, 2])\n",
            "torch.Size([5, 3, 4, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t19 = torch.empty(5, 1, 4, 1)\n",
        "t20 = torch.empty(3, 1, 1)\n",
        "print((t19 + t20).size())    # torch.Size([5, 3, 4, 1])\n",
        "\n",
        "t21 = torch.empty(1)\n",
        "t22 = torch.empty(3, 1, 7)\n",
        "print((t21 + t22).size())  # torch.Size([3, 1, 7])\n",
        "\n",
        "t23 = torch.ones(3, 3, 3)\n",
        "t24 = torch.ones(3, 1, 3)\n",
        "print((t23 + t24).size())  # torch.Size([3, 3, 3])\n",
        "\n",
        "# t25 = torch.empty(5, 2, 4, 1)\n",
        "# t26 = torch.empty(3, 1, 1)\n",
        "# print((t25 + t26).size())\n",
        "# RuntimeError: The size of tensor a (2) must match\n",
        "# the size of tensor b (3) at non-singleton dimension 1"
      ],
      "metadata": {
        "id": "NV-XFYn_f_wg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bdf382a8-ff9a-4891-bb1d-a9ddbc0bc84e"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([5, 3, 4, 1])\n",
            "torch.Size([3, 1, 7])\n",
            "torch.Size([3, 3, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t27 = torch.ones(4) * 5\n",
        "print(t27)  # >>> tensor([ 5, 5, 5, 5])\n",
        "\n",
        "t28 = torch.pow(t27, 2)   #제곱연산\n",
        "print(t28)  # >>> tensor([ 25, 25, 25, 25])\n",
        "\n",
        "exp = torch.arange(1., 5.)  # tensor([ 1.,  2.,  3.,  4.])\n",
        "a = torch.arange(1., 5.)  # tensor([ 1.,  2.,  3.,  4.])\n",
        "t29 = torch.pow(a, exp)\n",
        "print(t29)  # >>> tensor([   1.,    4.,   27.,  256.])"
      ],
      "metadata": {
        "id": "CaEfzwl1iW_L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0bb54af8-c8bf-4a7a-abf9-685cbdcaafde"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([5., 5., 5., 5.])\n",
            "tensor([25., 25., 25., 25.])\n",
            "tensor([  1.,   4.,  27., 256.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# j_tensor_indexing_slicing.py"
      ],
      "metadata": {
        "id": "Mmn49hpmvyJ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor(\n",
        "  [[0, 1, 2, 3, 4],\n",
        "   [5, 6, 7, 8, 9],\n",
        "   [10, 11, 12, 13, 14]]\n",
        ")\n",
        "\n",
        "print(x[1])  # >>> tensor([5, 6, 7, 8, 9]) ([1]의 행)\n",
        "print(x[:, 1])  # >>> tensor([1, 6, 11])   (행은 무한대, [1]의 열)\n",
        "print(x[1, 2])  # >>> tensor(7)            ([1]의 행, [2]의 열)\n",
        "print(x[:, -1])  # >>> tensor([4, 9, 14)   (행은 무한대, [-1]의 열)"
      ],
      "metadata": {
        "id": "yFsvYtpQwAEl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de6fa88b-e2ec-4537-b4d3-d040c4b8df44"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([5, 6, 7, 8, 9])\n",
            "tensor([ 1,  6, 11])\n",
            "tensor(7)\n",
            "tensor([ 4,  9, 14])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x[1:])  # >>> tensor([[ 5,  6,  7,  8,  9], [10, 11, 12, 13, 14]]) ([1] 이상의 행)\n",
        "print(x[1:, 3:])  # >>> tensor([[ 8,  9], [13, 14]]) ([1]이상의 행 & [3] 이상의 행)"
      ],
      "metadata": {
        "id": "iwsAGIcJihB0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b38b391d-544c-4b61-fbb2-fad2a01332df"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 5,  6,  7,  8,  9],\n",
            "        [10, 11, 12, 13, 14]])\n",
            "tensor([[ 8,  9],\n",
            "        [13, 14]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = torch.zeros((6, 6))   # 사이즈가 (6,6)이고 0으로 구성됨\n",
        "y[1:4, 2] = 1             # 행은 [1-3], 열은 [2]에 포함되는 곳을 1로 변경\n",
        "print(y)\n",
        "\n",
        "print(y[1:4, 1:4])"
      ],
      "metadata": {
        "id": "Col6_k5OijxC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb73dba3-54a1-47db-8886-6082fdde7805"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0.]])\n",
            "tensor([[0., 1., 0.],\n",
            "        [0., 1., 0.],\n",
            "        [0., 1., 0.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z = torch.tensor(\n",
        "  [[1, 2, 3, 4],\n",
        "   [2, 3, 4, 5],\n",
        "   [5, 6, 7, 8]]\n",
        ")\n",
        "print(z[:2])       #[2] 미만의 행\n",
        "print(z[1:, 1:3])  #[1] 이상의 행 & [1-2]의 열\n",
        "print(z[:, 1:])    # [1] 이상의 열\n",
        "\n",
        "z[1:, 1:3] = 0     # [1]이상의 행 & [1-2]의 열에 0 넣기\n",
        "print(z)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-l8Es2IimOW",
        "outputId": "9120e7ca-5b87-4231-e521-c1848c7c71bc"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 2, 3, 4],\n",
            "        [2, 3, 4, 5]])\n",
            "tensor([[3, 4],\n",
            "        [6, 7]])\n",
            "tensor([[2, 3, 4],\n",
            "        [3, 4, 5],\n",
            "        [6, 7, 8]])\n",
            "tensor([[1, 2, 3, 4],\n",
            "        [2, 0, 0, 5],\n",
            "        [5, 0, 0, 8]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# k_tensor_reshaping.py"
      ],
      "metadata": {
        "id": "X4Dlg9m5wCFk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 텐서의 모양 변경\n",
        "t1 = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
        "t2 = t1.view(3, 2)  # Shape becomes (3, 2)  (요소를 모양에 맞추어 배열, 요소 순서변경은 X)\n",
        "t3 = t1.reshape(1, 6)  # Shape becomes (1, 6)\n",
        "print(t2)\n",
        "print(t3)\n",
        "\n",
        "t4 = torch.arange(8).view(2, 4)  # Shape becomes (2, 4)\n",
        "t5 = torch.arange(6).view(2, 3)  # Shape becomes (2, 3)\n",
        "print(t4)\n",
        "print(t5)"
      ],
      "metadata": {
        "id": "90n744WrwFbZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63ae8bc7-57b9-4be3-efd6-2cb30a5575e1"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 2],\n",
            "        [3, 4],\n",
            "        [5, 6]])\n",
            "tensor([[1, 2, 3, 4, 5, 6]])\n",
            "tensor([[0, 1, 2, 3],\n",
            "        [4, 5, 6, 7]])\n",
            "tensor([[0, 1, 2],\n",
            "        [3, 4, 5]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Original tensor with shape (1, 3, 1)\n",
        "t6 = torch.tensor([[[1], [2], [3]]])\n",
        "\n",
        "# Remove all dimensions of size 1\n",
        "t7 = t6.squeeze()  # Shape becomes (3,) (차원 중 1인 것을 제거하여 생성됨)\n",
        "\n",
        "# Remove dimension at position 0\n",
        "t8 = t6.squeeze(0)  # Shape becomes (3, 1) (첫번째 차원 제거)\n",
        "print(t7)\n",
        "print(t8)"
      ],
      "metadata": {
        "id": "ACmRaRLtjNnr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c418d01e-81b1-4804-c021-ccdb67ac1f7a"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 2, 3])\n",
            "tensor([[1],\n",
            "        [2],\n",
            "        [3]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Original tensor with shape (3,)\n",
        "t9 = torch.tensor([1, 2, 3])\n",
        "\n",
        "# Add a new dimension at position 1\n",
        "t10 = t9.unsqueeze(1)  # Shape becomes (3, 1) (텐서의 차원 확장)\n",
        "print(t10)\n",
        "\n",
        "t11 = torch.tensor(\n",
        "  [[1, 2, 3],\n",
        "   [4, 5, 6]]\n",
        ")\n",
        "t12 = t11.unsqueeze(1)  # Shape becomes (2, 1, 3) (텐서의 차원 확장(기존 텐서의 두 번째 차원(인덱스1) 앞에 새로운 차원 추가))\n",
        "print(t12, t12.shape)"
      ],
      "metadata": {
        "id": "3K04WeCCjQD0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b4e32ec-7c68-4aee-aa70-da8bd2d7da82"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1],\n",
            "        [2],\n",
            "        [3]])\n",
            "tensor([[[1, 2, 3]],\n",
            "\n",
            "        [[4, 5, 6]]]) torch.Size([2, 1, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Original tensor with shape (2, 3)\n",
        "t13 = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
        "\n",
        "# Flatten the tensor\n",
        "t14 = t13.flatten()  # Shape becomes (6,) (1차원으로 flatten 시킴)\n",
        "\n",
        "print(t14)\n",
        "\n",
        "# Original tensor with shape (2, 2, 2)\n",
        "t15 = torch.tensor([[[1, 2],\n",
        "                     [3, 4]],\n",
        "                    [[5, 6],\n",
        "                     [7, 8]]])\n",
        "t16 = torch.flatten(t15)     # t15 flatten (1차원으로 flatten 됨)\n",
        "\n",
        "t17 = torch.flatten(t15, start_dim=1)    # [1] 이후를 flatten 시킴\n",
        "\n",
        "print(t16)\n",
        "print(t17)"
      ],
      "metadata": {
        "id": "8Z1y9u0qjQaE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3abb8367-e1cd-47a1-91e3-525250c36a18"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 2, 3, 4, 5, 6])\n",
            "tensor([1, 2, 3, 4, 5, 6, 7, 8])\n",
            "tensor([[1, 2, 3, 4],\n",
            "        [5, 6, 7, 8]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t18 = torch.randn(2, 3, 5)\n",
        "print(t18.shape)  # >>> torch.Size([2, 3, 5])\n",
        "print(torch.permute(t18, (2, 0, 1)).size())  # >>> 차원의 순서를 (2,0,1) 순으로 변경하기에 torch.Size([5, 2, 3])됨\n",
        "\n",
        "# Original tensor with shape (2, 3)\n",
        "t19 = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
        "\n",
        "# Permute the dimensions\n",
        "t20 = torch.permute(t19, dims=(0, 1))  # Shape becomes (2, 3)\n",
        "t21 = torch.permute(t19, dims=(1, 0))  # 차원을 (1,0)으로 변경하기에 shape은 (3, 2)가 된다\n",
        "print(t20)\n",
        "print(t21)\n",
        "\n",
        "# Transpose the tensor\n",
        "t22 = torch.transpose(t19, 0, 1)  # 차원 0,1을 사용하여 전치하기에 차원이 서로 바뀌어 shape은 (3, 2)가 된다\n",
        "\n",
        "print(t22)\n",
        "\n",
        "t23 = torch.t(t19)  # torch.t 함수를 이용해 차원을 전치시키기에 shape은 (3, 2)가 된다\n",
        "\n",
        "print(t23)"
      ],
      "metadata": {
        "id": "_x1Vzo_JjQd4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0ad31e3-63fb-4a11-984c-6bfb587f94cd"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 3, 5])\n",
            "torch.Size([5, 2, 3])\n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6]])\n",
            "tensor([[1, 4],\n",
            "        [2, 5],\n",
            "        [3, 6]])\n",
            "tensor([[1, 4],\n",
            "        [2, 5],\n",
            "        [3, 6]])\n",
            "tensor([[1, 4],\n",
            "        [2, 5],\n",
            "        [3, 6]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# l_tensor_contact.py"
      ],
      "metadata": {
        "id": "_Uok5snYwHIZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t1 = torch.zeros([2, 1, 3])\n",
        "t2 = torch.zeros([2, 3, 3])\n",
        "t3 = torch.zeros([2, 2, 3])\n",
        "\n",
        "t4 = torch.cat([t1, t2, t3], dim=1)        # 첫번째 차원을 연결 => 1+3+2 = 6\n",
        "print(t4.shape)"
      ],
      "metadata": {
        "id": "cVFqaRKRwLSh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b633cf28-c6e9-4b77-f0d4-436d2b28fa3c"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 6, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t5 = torch.arange(0, 3)  # (0부터 2까지) tensor([0, 1, 2])\n",
        "t6 = torch.arange(3, 8)  # (3부터 7까지) tensor([3, 4, 5, 6, 7])\n",
        "\n",
        "t7 = torch.cat((t5, t6), dim= 0)\n",
        "print(t7.shape)  # ([0,1,2,3,4,5,6,7]) torch.Size([8])\n",
        "print(t7)  #  tensor([0, 1, 2, 3, 4, 5, 6, 7])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DoGcs_Jg1Dv6",
        "outputId": "fda0862a-aa3f-4f04-e61f-8f168cf85f94"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8])\n",
            "tensor([0, 1, 2, 3, 4, 5, 6, 7])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t8 = torch.arange(0, 6).reshape(2, 3)   # 0에서 5까지 Size는 ([2, 3])\n",
        "t9 = torch.arange(6, 12).reshape(2, 3)  # 6에서 11까지 Size는 ([2, 3])\n",
        "\n",
        "# 2차원 텐서간 병합\n",
        "t10 = torch.cat((t8, t9), dim=0)        # 행방향을 기준으로 병합\n",
        "print(t10.size())                       # torch.Size([4, 3])\n",
        "print(t10)\n",
        "\n",
        "t11 = torch.cat((t8, t9), dim=1)        # 열방향을 기준으로 병합\n",
        "print(t11.size())                       # torch.Size([2, 6])\n",
        "print(t11)"
      ],
      "metadata": {
        "id": "IBgTAXyV1HTA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ffdf1b2-75a2-44fd-a6f3-563eea8faf9d"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3])\n",
            "tensor([[ 0,  1,  2],\n",
            "        [ 3,  4,  5],\n",
            "        [ 6,  7,  8],\n",
            "        [ 9, 10, 11]])\n",
            "torch.Size([2, 6])\n",
            "tensor([[ 0,  1,  2,  6,  7,  8],\n",
            "        [ 3,  4,  5,  9, 10, 11]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t12 = torch.arange(0, 6).reshape(2, 3)    # Size는 ([2, 3])\n",
        "t13 = torch.arange(6, 12).reshape(2, 3)   # Size는 ([2, 3])\n",
        "t14 = torch.arange(12, 18).reshape(2, 3)  # Size는 ([2, 3])\n",
        "\n",
        "t15 = torch.cat((t12, t13, t14), dim=0)   # 행방향을 기준으로\n",
        "print(t15.size())                         # Size는 ([6, 3])\n",
        "print(t15)\n",
        "\n",
        "\n",
        "t16 = torch.cat((t12, t13, t14), dim=1)   # 열방향을 기준으로\n",
        "print(t16.size())                         # Size는 ([2, 9])\n",
        "print(t16)"
      ],
      "metadata": {
        "id": "6Da_JdFM1HZN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5fdf7b38-9f2d-447c-d609-8fc4ef6a05aa"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([6, 3])\n",
            "tensor([[ 0,  1,  2],\n",
            "        [ 3,  4,  5],\n",
            "        [ 6,  7,  8],\n",
            "        [ 9, 10, 11],\n",
            "        [12, 13, 14],\n",
            "        [15, 16, 17]])\n",
            "torch.Size([2, 9])\n",
            "tensor([[ 0,  1,  2,  6,  7,  8, 12, 13, 14],\n",
            "        [ 3,  4,  5,  9, 10, 11, 15, 16, 17]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t17 = torch.arange(0, 6).reshape(1, 2, 3)   # 0부터 5까지 Size는 ([1, 2, 3])\n",
        "t18 = torch.arange(6, 12).reshape(1, 2, 3)  # 6부터 11까지 Size는 ([1, 2, 3])\n",
        "\n",
        "t19 = torch.cat((t17, t18), dim=0)          # 행방향을 기준으로\n",
        "print(t19.size())                           # Size는 ([2, 2, 3])\n",
        "print(t19)\n",
        "\n",
        "t20 = torch.cat((t17, t18), dim=1)          # 열방향을 기준으로\n",
        "print(t20.size())                           # Size는 ([1, 4, 3])\n",
        "print(t20)\n",
        "\n",
        "\n",
        "t21 = torch.cat((t17, t18), dim=2)          # 3번째 차원을 기준으로\n",
        "print(t21.size())                           # Size는 ([1, 2, 6])\n",
        "print(t21)"
      ],
      "metadata": {
        "id": "xe_MjyVo1Jy2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73e1adf6-3518-4ce1-cddc-5bbf49e02335"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 2, 3])\n",
            "tensor([[[ 0,  1,  2],\n",
            "         [ 3,  4,  5]],\n",
            "\n",
            "        [[ 6,  7,  8],\n",
            "         [ 9, 10, 11]]])\n",
            "torch.Size([1, 4, 3])\n",
            "tensor([[[ 0,  1,  2],\n",
            "         [ 3,  4,  5],\n",
            "         [ 6,  7,  8],\n",
            "         [ 9, 10, 11]]])\n",
            "torch.Size([1, 2, 6])\n",
            "tensor([[[ 0,  1,  2,  6,  7,  8],\n",
            "         [ 3,  4,  5,  9, 10, 11]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# m_tensor_stacking.py"
      ],
      "metadata": {
        "id": "6psR6HEfwOih"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t1 = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
        "t2 = torch.tensor([[7, 8, 9], [10, 11, 12]])\n",
        "\n",
        "t3 = torch.stack([t1, t2], dim=0)  # 행방향을 기준으로 텐서 생성\n",
        "t4 = torch.cat([t1.unsqueeze(dim=0), t2.unsqueeze(dim=0)], dim=0)   #t1과 t2를 첫번째 차원에서 확장한 후 행방향을 기준으로 텐서 생성함\n",
        "print(t3.shape, t3.equal(t4))\n",
        "\n",
        "t5 = torch.stack([t1, t2], dim=1)  # 열방향을 기준으로 텐서 생성\n",
        "t6 = torch.cat([t1.unsqueeze(dim=1), t2.unsqueeze(dim=1)], dim=1)   #t1과 t2를 두번째 차원에서 확장한 후 열방향을 기준으로 텐서 생성함\n",
        "print(t5.shape, t5.equal(t6))\n",
        "\n",
        "t7 = torch.stack([t1, t2], dim=2)  # 3번째 차원을 기준으로 텐서 생성\n",
        "t8 = torch.cat([t1.unsqueeze(dim=2), t2.unsqueeze(dim=2)], dim=2)   #t1과 t2를 세번째 차원에서 확장한 후 3번째 차원을 기준으로 텐서 생성함\n",
        "print(t7.shape, t7.equal(t8))"
      ],
      "metadata": {
        "id": "uYeQXPjewSeR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63c115e3-82a2-4c29-b04d-719c0d7bde99"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 2, 3]) True\n",
            "torch.Size([2, 2, 3]) True\n",
            "torch.Size([2, 3, 2]) True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t9 = torch.arange(0, 3)       # tensor([0, 1, 2])\n",
        "t10 = torch.arange(3, 6)      # tensor([3, 4, 5])\n",
        "\n",
        "print(t9.size(), t10.size())  # t9의 Size는 ([3]), t1의 Size는 ([3])\n",
        "\n",
        "t11 = torch.stack((t9, t10), dim=0)  # 행방향을 기준으로 텐서 생성\n",
        "print(t11.size())                    # Size는 ([2,3])\n",
        "print(t11)\n",
        "\n",
        "t12 = torch.cat((t9.unsqueeze(0), t10.unsqueeze(0)), dim=0)   #t9과 t10을 첫번째 차원에서 확장한 후 행방향을 기준으로 텐서 생성함\n",
        "print(t11.equal(t12))\n",
        "\n",
        "t13 = torch.stack((t9, t10), dim=1)  # 열방향을 기준으로 텐서 생성\n",
        "print(t13.size())                    # Size는 ([3,2])\n",
        "print(t13)\n",
        "\n",
        "t14 = torch.cat((t9.unsqueeze(1), t10.unsqueeze(1)), dim=1)   #t9과 t10을 두번째 차원에서 확장한 후 열방향을 기준으로 텐서 생성함\n",
        "print(t13.equal(t14))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "znkLw9ae2aZI",
        "outputId": "d578889e-70a9-4f2d-8949-68e69aac714a"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3]) torch.Size([3])\n",
            "torch.Size([2, 3])\n",
            "tensor([[0, 1, 2],\n",
            "        [3, 4, 5]])\n",
            "True\n",
            "torch.Size([3, 2])\n",
            "tensor([[0, 3],\n",
            "        [1, 4],\n",
            "        [2, 5]])\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#n_tensor_vstack_hstack.py"
      ],
      "metadata": {
        "id": "V0jyflUMwUXO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t1 = torch.tensor([1, 2, 3])\n",
        "t2 = torch.tensor([4, 5, 6])\n",
        "t3 = torch.vstack((t1, t2))         # t1과 t2를 수직으로 쌓아서 새로운 2차원 텐서 생성\n",
        "print(t3)\n",
        "\n",
        "t4 = torch.tensor([[1], [2], [3]])\n",
        "t5 = torch.tensor([[4], [5], [6]])\n",
        "t6 = torch.vstack((t4, t5))         # t4과 t5를 수직으로 쌓아서 새로운 2차원 텐서 생성\n",
        "\n",
        "\n",
        "t7 = torch.tensor([\n",
        "  [[1, 2, 3], [4, 5, 6]],\n",
        "  [[7, 8, 9], [10, 11, 12]]\n",
        "])\n",
        "print(t7.shape)                     # shape는 (2, 2, 3)\n",
        "\n",
        "t8 = torch.tensor([\n",
        "  [[13, 14, 15], [16, 17, 18]],\n",
        "  [[19, 20, 21], [22, 23, 24]]\n",
        "])\n",
        "print(t8.shape)                     # shape는 (2, 2, 3)\n",
        "\n",
        "t9 = torch.vstack([t7, t8])         # t7과 t8를 수직으로 쌓아서 새로운 3차원 텐서 생성\n",
        "print(t9.shape)                     # shape는 (4, 2, 3)\n",
        "\n",
        "print(t9)"
      ],
      "metadata": {
        "id": "Z1MhBhwywYpE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40a47d75-4015-4815-8826-d0512e78b672"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6]])\n",
            "torch.Size([2, 2, 3])\n",
            "torch.Size([2, 2, 3])\n",
            "torch.Size([4, 2, 3])\n",
            "tensor([[[ 1,  2,  3],\n",
            "         [ 4,  5,  6]],\n",
            "\n",
            "        [[ 7,  8,  9],\n",
            "         [10, 11, 12]],\n",
            "\n",
            "        [[13, 14, 15],\n",
            "         [16, 17, 18]],\n",
            "\n",
            "        [[19, 20, 21],\n",
            "         [22, 23, 24]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t10 = torch.tensor([1, 2, 3])\n",
        "t11 = torch.tensor([4, 5, 6])\n",
        "t12 = torch.hstack((t10, t11))      # t10과 t11을 수평으로 결합해서 새로운 텐서 생성\n",
        "print(t12)\n",
        "\n",
        "t13 = torch.tensor([[1], [2], [3]])\n",
        "t14 = torch.tensor([[4], [5], [6]])\n",
        "t15 = torch.hstack((t13, t14))      # t13과 t14를 수평으로 결합해서 새로운 텐서 생성\n",
        "print(t15)\n",
        "\n",
        "t16 = torch.tensor([\n",
        "  [[1, 2, 3], [4, 5, 6]],\n",
        "  [[7, 8, 9], [10, 11, 12]]\n",
        "])\n",
        "print(t16.shape)                     # shape는 (2, 2, 3)\n",
        "\n",
        "t17 = torch.tensor([\n",
        "  [[13, 14, 15], [16, 17, 18]],\n",
        "  [[19, 20, 21], [22, 23, 24]]\n",
        "])\n",
        "print(t17.shape)                     # shape는 (2, 2, 3)\n",
        "\n",
        "\n",
        "t18 = torch.hstack([t16, t17])       # t16과 t17을 수평으로 결합해서 새로운 3차원 텐서 생성\n",
        "print(t18.shape)                     # shape는 (2, 4, 3)\n",
        "\n",
        "print(t18)"
      ],
      "metadata": {
        "id": "W9x0yxwr39ra",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14c312a4-c086-4032-9dba-b0424a4e2c97"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 2, 3, 4, 5, 6])\n",
            "tensor([[1, 4],\n",
            "        [2, 5],\n",
            "        [3, 6]])\n",
            "torch.Size([2, 2, 3])\n",
            "torch.Size([2, 2, 3])\n",
            "torch.Size([2, 4, 3])\n",
            "tensor([[[ 1,  2,  3],\n",
            "         [ 4,  5,  6],\n",
            "         [13, 14, 15],\n",
            "         [16, 17, 18]],\n",
            "\n",
            "        [[ 7,  8,  9],\n",
            "         [10, 11, 12],\n",
            "         [19, 20, 21],\n",
            "         [22, 23, 24]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<고찰>\n",
        "이번 과제를 통해 솔직히 개념적으로만 이해했고 헷갈렸던 텐서의 개념과 텐서와 데이터타입, 요소들의 개념에 대해 확실히 이해할 수 있었다.\n",
        "이 과제는 텐서를 만들고 결합하고, 나누고, 확장하고, 제거하는 등의 학습을 통해 텐서가 어떻게 달라지는지를 관찰하고, 이해하면서 한결 더 나은 개념이 잡혔다고 생각한다."
      ],
      "metadata": {
        "id": "4JHlgyUK4xMb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<숙제후기>\n",
        "컴퓨터에 pycharm, git, anaconda를 깔면서, 솔직히 지금도 환경 조성이 안되어서 급하게 노트북을 빌려 과제를 해결하였다.\n",
        "처음 pytorch를 까는 과정에서 오류가 한번 생기니, pytorch를 지웠다가 다시 깔아도 애초에 pytorch에서 에러가 생겼다.\n",
        "직접 나의 노트북으로 이번 과제를 해결하고 싶었지만, 이번 과제는 불가능하다고 판단해 다음 과제부터는 나의 노트북으로 해결할 수 있도록, 한번 더 시도해보아야 겠다."
      ],
      "metadata": {
        "id": "6LywmYJ36vCa"
      }
    }
  ]
}